import streamlit as st
import pandas as pd
import pydeck as pdk
import plotly.express as px
import os
import re

# ==========================================
# ğŸ‘‡ 1. ç”¨æˆ·é…ç½®åŒºåŸŸ (å·²ä¿®æ”¹ä¸ºç›¸å¯¹è·¯å¾„ï¼Œé€‚é…äº‘ç«¯éƒ¨ç½²)
# ==========================================
LOCATIONS_CSV_PATH = "å„’æ—å¤–å²_7_Cities.csv"
TXT_FILE_PATH = "æ€».txt"
CHAPTER_INFO_PATH = "chapter_data.xlsx"
# ==========================================

# 2. é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(
    page_title="å„’æ—å¤–å²åœ°ç‚¹åˆ†æ",
    page_icon="ğŸ—ºï¸",
    layout="wide"
)

# --- å®šä¹‰åœ°ç‚¹å­—å…¸ (ç”¨äºåˆ†ç« èŠ‚ç»Ÿè®¡åŸæ–‡) ---
LOCATIONS_DB = [
    {"name": "æ­å· (Hangzhou)",
     "aliases": ["æ­å·", "æ­åŸ", "è¥¿æ¹–", "çœåŸ", "æ­¦æ—", "éŒ¢å¡˜", "æ–·æ²³é ­", "æ¸…æ³¢é–€", "ä»å’Œ", "éŒ¢å¡˜é–€", "éˆéš±", "å¤©ç«º",
                 "è˜‡å ¤", "é›·å³°", "æ·¨æ…ˆ", "åŸéšå±±", "å³å±±"]},
    {"name": "æ¹–å· (Huzhou)", "aliases": ["æ¹–å·", "é¶¯è„°æ¹–", "æ–°å¸‚é®", "é›™æ—", "å©åºœ", "çƒç¨‹"]},
    {"name": "åŒ—äº¬ (Beijing)",
     "aliases": ["åŒ—äº¬", "äº¬å¸«", "äº¬è£", "äº¬åŸ", "éƒ½é–€", "é­é—•", "é•·å®‰", "é †å¤©åºœ", "å…§å»·", "å…¥äº¬", "é€²äº¬"]},
    {"name": "å—äº¬ (Nanjing)", "aliases": ["å—äº¬", "é‡‘é™µ", "ç™½ä¸‹", "å»ºåº·", "æ‡‰å¤©"]},
    {"name": "æšå· (Yangzhou)", "aliases": ["æšå·", "å»£é™µ", "ç¶­æš", "æ±Ÿéƒ½"]},
    {"name": "æ¿Ÿå— (Jinan)", "aliases": ["æ¿Ÿå—", "æ­·ä¸‹"]},
    {"name": "è˜‡å· (Suzhou)", "aliases": ["è˜‡å·", "å§‘è˜‡", "å³é–€", "å¹³æ±Ÿ"]},
    {"name": "æº«å· (Wenzhou)", "aliases": ["æº«å·", "æ¨‚æ¸…"]},
    {"name": "ç´¹èˆˆ (Shaoxing)", "aliases": ["ç´¹èˆˆ", "æœƒç¨½", "è¶ŠåŸ"]}
]


# 3. æ•°æ®åŠ è½½å‡½æ•°
@st.cache_data
def load_map_data():
    if not os.path.exists(LOCATIONS_CSV_PATH): return None
    return pd.read_csv(LOCATIONS_CSV_PATH, encoding="utf-8-sig")


@st.cache_data
def load_text_data():
    if not os.path.exists(TXT_FILE_PATH): return None
    with open(TXT_FILE_PATH, "r", encoding="utf-8") as f:
        return f.read()


@st.cache_data
def load_chapter_info():
    if not os.path.exists(CHAPTER_INFO_PATH): return None
    try:
        # ä½¿ç”¨ read_excel è¯»å– .xlsxï¼ŒæŒ‡å®š engine
        return pd.read_excel(CHAPTER_INFO_PATH, engine='openpyxl')
    except Exception as e:
        st.error(f"è¯»å– Excel å¤±è´¥: {e}")
        return None


@st.cache_data
def process_chapter_stats(text):
    """å°†æ–‡æœ¬æŒ‰ç« èŠ‚åˆ‡åˆ†å¹¶ç»Ÿè®¡åœ°ç‚¹é¢‘æ¬¡"""
    chapters = re.split(r'(?=\*[^\n]+)', text)
    chapter_data = []
    for chapter in chapters:
        if not chapter.strip(): continue
        lines = chapter.split('\n')
        title = lines[0].replace('*', '').strip()
        short_title = title.split(' ')[0] if ' ' in title else title[:6]

        row = {"Chapter": short_title, "Full_Title": title}
        for loc in LOCATIONS_DB:
            count = 0
            for alias in loc["aliases"]:
                count += chapter.count(alias)
            row[loc["name"]] = count
        chapter_data.append(row)
    return pd.DataFrame(chapter_data)


# æ‰§è¡ŒåŠ è½½
df_map = load_map_data()
full_text = load_text_data()
df_info = load_chapter_info()

# é”™è¯¯æ£€æŸ¥
if df_map is None or full_text is None:
    st.error("âŒ ç¼ºå°‘åŸºç¡€æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ GitHub ä»“åº“ä¸­æ˜¯å¦ä¸Šä¼ äº† csv å’Œ txt æ–‡ä»¶ã€‚")
    st.stop()

df_stats = process_chapter_stats(full_text)

# ==========================================
# 4. ç•Œé¢å¸ƒå±€
# ==========================================

st.title("ğŸ—ºï¸ ã€Šå„’æ—å¤–å²ã€‹ç¬¬10-20å›ç©ºé—´åˆ†æ")
st.markdown("""
**Digital Humanities Analysis of *The Scholars* (Ch. 10-20)**
æœ¬åº”ç”¨ç»“åˆäº†**GISç©ºé—´åˆ†æ**ä¸**æ–‡æœ¬ç»†è¯»**ï¼Œä¸»è¦æ¢è®¨å£«äººåœ¨ååˆ©åœºï¼ˆæ­å·ï¼‰ä¸æƒåŠ›ä¸­å¿ƒï¼ˆåŒ—äº¬ï¼‰ä¹‹é—´çš„æµåŠ¨ã€‚
""")
st.markdown("---")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ“Š æ•°æ®æ§åˆ¶å°")
    st.success(f"âœ… å·²åŠ è½½åœ°ç‚¹æ•°æ®: {len(df_map)} ä¸ª")
    if df_info is not None:
        st.success(f"âœ… å·²åŠ è½½æƒ…èŠ‚æ•°æ®: {len(df_info)} ç« ")
    else:
        st.warning("âš ï¸ æœªæ‰¾åˆ°ç« èŠ‚æƒ…èŠ‚ Excel æ–‡ä»¶")

    st.markdown("---")
    st.write("**åœ°å›¾æ•°æ®é¢„è§ˆ:**")
    st.dataframe(df_map, use_container_width=True)

# --- Tab å¸ƒå±€ç®¡ç†æ‰€æœ‰å†…å®¹ ---
tab_map, tab_trend, tab_details, tab_insight, tab_route = st.tabs([
    "ğŸ“ ç©ºé—´åˆ†å¸ƒ (Map)",
    "ğŸ“ˆ åŠ¨æ€æ¼”å˜ (Trend)",
    "ğŸ“– ç« èŠ‚è¯¦æƒ… (Details)",
    "ğŸ§ æ·±åº¦åˆ†æ (Insights)",
    "ğŸš€ äººç‰©è½¨è¿¹ (Route)"
])

# === TAB 1: åœ°å›¾ä¸æ’å ===
with tab_map:
    col1, col2 = st.columns([3, 2])
    with col1:
        st.subheader("åœ°ç‚¹é¢‘æ¬¡åœ°å›¾")
        layer = pdk.Layer(
            "ScatterplotLayer",
            df_map,
            get_position='[Lon, Lat]',
            get_color='[200, 30, 0, 160]',
            get_radius='Frequency * 4000',
            pickable=True,
            auto_highlight=True
        )
        view_state = pdk.ViewState(latitude=31.0, longitude=119.0, zoom=5)
        st.pydeck_chart(pdk.Deck(
            map_provider="carto",
            map_style="light",
            initial_view_state=view_state,
            layers=[layer],
            tooltip={"html": "<b>{Name}</b><br/>é¢‘æ¬¡: {Frequency}<br/>æ€§è´¨: {Type}"}
        ))
    with col2:
        st.subheader("æ€»é¢‘æ¬¡æ’å")
        fig_bar = px.bar(df_map.sort_values('Frequency', ascending=True), x='Frequency', y='Name', orientation='h',
                         color='Type')
        st.plotly_chart(fig_bar, use_container_width=True)

# === TAB 2: è¶‹åŠ¿åˆ†æ ===
with tab_trend:
    st.subheader("åœ°ç‚¹åœ¨å„ç« èŠ‚çš„æ´»è·ƒåº¦")
    cities_list = [loc["name"] for loc in LOCATIONS_DB]
    df_heatmap = df_stats.melt(id_vars=["Chapter", "Full_Title"], value_vars=cities_list, var_name="City",
                               value_name="Count")

    fig_heatmap = px.density_heatmap(
        df_heatmap, x="Chapter", y="City", z="Count", color_continuous_scale="Reds",
        labels={"Chapter": "ç« èŠ‚", "City": "åŸå¸‚", "Count": "é¢‘æ¬¡"}, height=500
    )
    st.plotly_chart(fig_heatmap, use_container_width=True)

# === TAB 3: ç« èŠ‚è¯¦æƒ… (è¯»å– Excel æ•°æ®) ===
with tab_details:
    st.header("ğŸ“– ç« èŠ‚äººç‰©ä¸æƒ…èŠ‚å¯¹ç…§")

    if df_info is not None:
        if 'CHAPTER' in df_info.columns:
            chapter_list = df_info['CHAPTER'].unique()
            selected_chapter = st.selectbox("è¯·é€‰æ‹©è¦æŸ¥çœ‹çš„ç« èŠ‚:", chapter_list)

            chapter_row = df_info[df_info['CHAPTER'] == selected_chapter].iloc[0]

            c1, c2 = st.columns([1, 2])

            with c1:
                st.info("### ğŸ­ å…³é”®äººç‰©")
                chars = str(chapter_row.get('CHARACTERS', 'æ— æ•°æ®')).replace('\n', '  \n')
                st.markdown(chars)

            with c2:
                st.warning("### âš¡ å…³é”®äº‹ä»¶")
                events = str(chapter_row.get('MAIN PLOTS', 'æ— æ•°æ®')).replace('\n', '  \n')
                st.markdown(events)

            with st.expander("æŸ¥çœ‹æœ¬ç« å°ç»“ (Summary)", expanded=True):
                st.write(chapter_row.get('SUMMARY', 'æ— æ•°æ®'))
        else:
            st.error("Excel æ–‡ä»¶åˆ—åä¸åŒ¹é…ï¼Œè¯·æ£€æŸ¥æ˜¯å¦åŒ…å« 'CHAPTER', 'CHARACTERS', 'MAIN PLOTS', 'SUMMARY'")
    else:
        st.error(f"è¯·ç¡®ä¿ä¸Šä¼ äº† '{CHAPTER_INFO_PATH}' æ–‡ä»¶ã€‚")

# === TAB 4: æ·±åº¦åˆ†æ ===
with tab_insight:
    st.subheader("Insights: ç©ºé—´ä¸é“å¾·çš„æµåŠ¨")

    st.markdown("""
    ### 1. æ–‡åŒ–ç©ºé—´çš„äºŒå…ƒå¯¹ç«‹ï¼šç¦»å¿ƒåŒ–çš„å¸‚æ°‘ç¤¾ä¼šä¸å‘å¿ƒåŒ–çš„æƒåŠ›æœºå™¨
    * **ä½œä¸ºâ€œç¦»å¿ƒåŒ–å¸‚æ°‘ç¤¾ä¼šâ€çš„æ­å·**ï¼šæ­å·å‘ˆç°ä¸ºä¸€ä¸ª**å»ä¸­å¿ƒã€å¤šèŠ‚ç‚¹ã€è‡ªç»„ç»‡**çš„ååˆ©ç”Ÿæ€åœˆ...
    * **ä½œä¸ºâ€œå‘å¿ƒåŒ–æƒåŠ›æœºå™¨â€çš„åŒ—äº¬**ï¼šåŒ—äº¬åˆ™ä½œä¸ºä¸€ä¸ª**å‚ç›´çš„ã€ç­‰çº§æ£®ä¸¥çš„ç»ˆææƒåŠ›åœº**è€Œå­˜åœ¨...

    ### 2. åŒ¡è¶…äººçš„å •è½è½¨è¿¹ (Spatial Narrative of Moral Degeneration)
    * **ä½œä¸ºâ€œç©ºé—´ç©¿è¶Šè€…â€çš„åŒ¡è¶…äºº**ï¼šä»–æ˜¯**ä¸€ä¸ªåœ¨å¸å›½æ ¸å¿ƒæ–‡åŒ–ç©ºé—´ä¸­ä¸æ–­è¿å¾™çš„æ ·æœ¬**...
    * **æ€æƒ³å±‚é¢**ï¼šä»å„’å®¶ä¼¦ç†åˆ°å½»åº•çš„åŠŸåˆ©ä¸»ä¹‰...
    * **æ‚²å‰§æ€§ç©ºé—´è±¡å¾**ï¼šæ­å·çš„æ–‡ç€šæ¥¼ã€åŒ—äº¬çš„å©šæˆ¿...

    ### 3. é©¬äºŒå…ˆç”Ÿçš„åšå®ˆä¸æ‚–è®º (The Persistence of Ma Chunshang)
    * **æ–‡åŒ–ç©ºé—´çš„äºŒå…ƒå¯¹ç«‹**ï¼šä½“åˆ¶å®ˆæŠ¤è€…ä¸æ±Ÿæ¹–è½é­„äºº...
    * **é©¬äºŒå…ˆç”Ÿçš„äººæ ¼ç»“æ„è§£æ**ï¼šè¢«å…«è‚¡å½»åº•è§„è®­çš„â€œå¥—ä¸­äººâ€ vs æ±Ÿæ¹–é“ä¹‰çš„è·µè¡Œè€…...
    """)

    st.divider()
    st.subheader("åŸæ–‡å…³é”®è¯æ£€ç´¢")
    search_term = st.text_input("è¾“å…¥å…³é”®è¯ (ç¹ä½“)", "è¥¿æ¹–", key="search_term_input")

    if search_term:
        paragraphs = full_text.replace("\\r", "").split("\\n")
        if len(paragraphs) < 2: paragraphs = full_text.split("\n")
        count = 0
        for p in paragraphs:
            if search_term in p:
                st.markdown(f"**...{p.strip()}...**")
                st.divider()
                count += 1
                if count >= 3: break
        if count == 0: st.warning("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")

# === TAB 5: äººç‰©è½¨è¿¹ (æ–°å¢) ===
with tab_route:
    # å®šä¹‰è·¯çº¿æ•°æ®
    ROUTES_DATA = [
        {
            "name": "åŒ¡è¶…äºº (Kuang Chaoren)",
            "color": [255, 0, 0],
            "path": [[120.98, 28.12], [120.15, 30.27], [120.58, 30.00], [120.15, 30.27], [119.41, 32.39],
                     [116.40, 39.90]],
            "chapters": "ç¬¬15-20å›"
        },
        {
            "name": "é©¬äºŒå…ˆç”Ÿ (Ma Chunshang)",
            "color": [0, 128, 255],
            "path": [[120.75, 30.75], [120.15, 30.27]],
            "chapters": "ç¬¬13-15å›"
        },
        {
            "name": "ç‰›å¸ƒè¡£ (Niu Buyi)",
            "color": [0, 128, 0],
            "path": [[120.58, 30.00], [120.08, 30.89], [119.41, 32.39], [118.37, 31.35]],
            "chapters": "ç¬¬10, 20å›"
        }
    ]

    st.subheader("ğŸš€ äººç‰©è¡ŒåŠ¨è½¨è¿¹")
    c_map, c_info = st.columns([3, 1])

    with c_map:
        view_state_route = pdk.ViewState(latitude=32.0, longitude=118.0, zoom=5)
        layer_routes = pdk.Layer("PathLayer", ROUTES_DATA, pickable=True, get_color="color", width_scale=20,
                                 width_min_pixels=3, get_path="path", get_width=5)

        all_points = []
        for r in ROUTES_DATA:
            for p in r['path']:
                all_points.append({"coord": p, "name": r['name'], "color": r['color']})
        layer_points = pdk.Layer("ScatterplotLayer", all_points, get_position="coord", get_color="color",
                                 get_radius=8000, pickable=True)

        st.pydeck_chart(pdk.Deck(
            map_provider="carto", map_style="light", initial_view_state=view_state_route,
            layers=[layer_routes, layer_points],
            tooltip={"html": "<b>{name}</b><br/>æ´»åŠ¨ç« èŠ‚: {chapters}",
                     "style": {"backgroundColor": "steelblue", "color": "white"}}
        ))

    with c_info:
        st.markdown("#### ğŸ”´ åŒ¡è¶…äºº")
        st.caption("è·¯çº¿ï¼šæ¸©å· -> åŒ—äº¬")
        st.write("ä»è¾¹ç¼˜å‘ä¸­å¿ƒçš„å •è½ä¹‹è·¯ã€‚")
        st.divider()
        st.markdown("#### ğŸ”µ é©¬äºŒå…ˆç”Ÿ")
        st.caption("è·¯çº¿ï¼šå˜‰å…´ -> æ­å·")
        st.write("åšå®ˆæ±Ÿå—çš„å„’å®¶æ­£ç»Ÿã€‚")
        st.divider()
        st.markdown("#### ğŸŸ¢ ç‰›å¸ƒè¡£")
        st.caption("è·¯çº¿ï¼šæ¹–å· -> èŠœæ¹–")
        st.write("æ¼‚æ³Šå®¢æ­»ä»–ä¹¡çš„æ‚²å‡‰ã€‚")

st.caption("Created by Streamlit | Data Source: Ctext.org")